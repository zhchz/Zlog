<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Zlog</title>
  
  
  <link href="https://zrzfh.github.io/Zlog/atom.xml" rel="self"/>
  
  <link href="https://zrzfh.github.io/Zlog/"/>
  <updated>2023-04-17T01:10:29.267Z</updated>
  <id>https://zrzfh.github.io/Zlog/</id>
  
  <author>
    <name>zrzfh</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>机器学习基础（一）概率论</title>
    <link href="https://zrzfh.github.io/Zlog/probability/"/>
    <id>https://zrzfh.github.io/Zlog/probability/</id>
    <published>2023-04-03T08:06:15.000Z</published>
    <updated>2023-04-17T01:10:29.267Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言">引言</h1><p>不确定性可以说是在用数学工具对世界进行建模和认知的时候不可回避的问题，也是机器学习中的一个最基本的概念。于是，我们需要对这种不确定性进行量化和计算，而概率论能够为此提供一个合理的框架。所以，概率论是机器学习中最重要的基础理论之一，这也是本文要详细梳理概率论的基础知识的出发点。如果再辅之以其他工具如决策论、线性代数、微积分等，还能够在让我们构建世界观的同时，有切实可用的方法论。</p><span id="more"></span><p>本文会尽可能全面的列出机器学习中涉及到概率论的重要的基础的公理、定理、推理、定义、算法等，给出重要的公式、流程，但不会涉及证明和详细推导过程，作为梳理和备用，适用于入门和需要快速了解相关原理的情形，渴望更深层次的理解和探讨，建议系统的阅读相关资料书籍。</p><h1 id="随机变量与概率">随机变量与概率</h1><p>首先，我们简单的回顾一下随机事件、随机变量、概率等基本的概念。</p><h2 id="随机事件和随机变量">随机事件和随机变量</h2><p>对于不总是出现同一个结果的现象，我们称之为 <strong> 随机现象 </strong>，随机现象所有的可能结果组成了<strong> 样本空间 </strong>，而样本空间中的一个或者几个点集被称为<strong> 随机事件</strong>，通常使用<span class="math inline">\(A, B, C, ...\)</span> 等大写字母表示。</p><p>于是，用于表示随机事件的结果的数学变量，被称作 <strong> 随机变量</strong>，在一般数学表达上使用<span class="math inline">\(X, Y, Z\)</span>这样的大写字母。随机变量可以用来表示随机事件或者随机事件的组合，于是涉及到了随机事件之间的关系和运算法则。</p><p>总的来说，随机事件的关系包括：<strong>包含关系 </strong>，<strong> 相等关系 </strong>，<strong> 互不相容</strong>。包含关系是指，事件<span class="math inline">\(A\)</span> 是事件 <spanclass="math inline">\(B\)</span> 的子集，<spanclass="math inline">\(A\)</span> 的发生必然导致 <spanclass="math inline">\(B\)</span> 的发生，用 <spanclass="math inline">\(A \subset B\)</span> 表示。相等关系是指，事件<span class="math inline">\(A\)</span> 和事件 <spanclass="math inline">\(B\)</span> 相互包含，用 <spanclass="math inline">\(A = B\)</span> 表示 。互不相容表示，事件 <spanclass="math inline">\(A\)</span> 和事件 <spanclass="math inline">\(B\)</span> 没有交集，<spanclass="math inline">\(A\)</span> 和 <spanclass="math inline">\(B\)</span> 不可能同时发生，用 <spanclass="math inline">\(A \cap B = \varnothing\)</span> 表示。</p><p>随机事件的运算法则包含 <strong> 并</strong>，<strong>交 </strong>，<strong> 差</strong>，<strong>余</strong>。并：事件<span class="math inline">\(A\)</span> 或者事件 <spanclass="math inline">\(B\)</span> 至少有一个发生，用 <spanclass="math inline">\(A \cup B\)</span> 表示；交：事件 <spanclass="math inline">\(A\)</span> 和事件 <spanclass="math inline">\(B\)</span> 同时发生，用 <spanclass="math inline">\(A \cap B\)</span> 表示；差：事件 <spanclass="math inline">\(A\)</span> 发生，且事件 <spanclass="math inline">\(B\)</span> 不发生，用减号 <spanclass="math inline">\(A - B\)</span> 表示；余：事件 <spanclass="math inline">\(A\)</span> 和事件 <spanclass="math inline">\(B\)</span> 只能有一个发生（其实就是非的意思），用<span class="math inline">\(A = \bar{B}\)</span>表示。以上运算都满足交换律、结合律和分配律，还满足德摩根定律（DeMorgan's laws），也称作反演律，没有什么神奇的，表达式是：<spanclass="math inline">\(\overline{A \cap B} = \bar{A} \cup\bar{B}\)</span>。</p><h2 id="概率">概率</h2><p>确定事件的概率，常用的方法有频率方法、古典方法、几何方法。</p><p>频率方法，是观察事件 <span class="math inline">\(A\)</span>大量重复实验，记录 <span class="math inline">\(A\)</span>出现的次数，也称作 <strong> 频数</strong>，频数与总实验数之比记作 <spanclass="math inline">\(A\)</span> 的概率，即 <spanclass="math inline">\(p(A) =\frac{n(A)}{N}\)</span>，实践表明随着实验次数的增加，该比值将稳定在真实值附近，但是受到实验次数不能无限进行的限制，该方法只能得到近似的估计值。</p><p>古典方法，是在经验的基础上，通过逻辑分析总结得到概率的计算表达式，基本的计算方法是利用事件<span class="math inline">\(A\)</span>在样本空间中所占有的个数与样本空间中所有样本点的个数之比计算 <spanclass="math inline">\(A\)</span> 的概率，也就是 <spanclass="math inline">\(P(A) = \frac{N_A}{N}\)</span>。</p><p>几何方法，利用几何工具的辅助，假设样本空间内各处是等可能的，有一个事件的可能充满某一子区域，然后就用这个子区域占整体区域的大小来表示这个区域代表的事件<span class="math inline">\(A\)</span> 的概率，写成 <spanclass="math inline">\(P(A) = \frac{S_A}{S}\)</span>。</p><p>此外，还有根据个人的经验和主观判断来定义事件发生的概率，俗话说就是凭感觉，当然这不能是玄学的范畴。</p><p>当然，概率有一些性质和计算规则。比如，<spanclass="math inline">\(P(\varnothing) = 0\)</span>，不可能事件的概率为0，<span class="math inline">\(P(\Omega) = 1\)</span>，<spanclass="math inline">\(\Omega\)</span> 是整个样本空间，必然事件的概率为1。</p><p>概率是可加的，例如若干个 <strong> 互不相容 </strong> 的事件 <spanclass="math inline">\(A_1, A_2, A_3, \cdots, A_n\)</span> 的概率之和为<span class="math display">\[P(A_{\sum}) = \sum_{i} P(A_i)\]</span></p><p>如果对于一般事件，那么就要使用加法公式了 <spanclass="math display">\[P(A \cup B) = P(A) + P(B) - P(A \cap B)\]</span>可以想象两个重叠了一部分的矩形，要求重叠的面积，那么对两个矩形面积求和后还要减去它们中间重叠的部分，这就是加法公式的意义。于是，自然的有一个不等式推论，即<span class="math inline">\(P(A \cup B) \leq P(A) + P(B)\)</span>。</p><h1 id="条件概率和独立性">条件概率和独立性</h1><h2 id="条件概率">条件概率</h2><p><strong>条件概率 </strong> 的定义是在某一个事件 <spanclass="math inline">\(B\)</span> 发生的情况下，求另一个事件 <spanclass="math inline">\(A\)</span> 发生的概率，记作 <spanclass="math inline">\(P(A|B)\)</span>，定义为 <spanclass="math display">\[P(A|B) = \frac{P(AB)}{P(B)}\]</span> 其中重要的一点是 <span class="math inline">\(P(B) &gt;0\)</span>。 ## 乘法公式<strong>乘法公式 </strong> 可以直接从上式推导出，若 <spanclass="math inline">\(P(B) &gt; 0\)</span>，则 <spanclass="math display">\[P(AB) = P(B)P(A|B)\]</span> 在机器学习中，更为常见的是乘法公式的一般式子，设 <spanclass="math inline">\(P(A_1 A_2 A_3 \cdots A_{n-1}) &gt;0\)</span>，则有 <span class="math display">\[P(A_1 \cdots A_n) = P(A_1) P(A_2|A_1) P(A_3|A_1 A_2) \cdots P(A_n| A_1\cdots A_{n-1})\]</span></p><h2 id="全概率公式">全概率公式</h2><p><strong>全概率公式 </strong> 定义为 <span class="math display">\[P(A) = \sum_{i=1}^{n}{P(B_i)P(A|B_i)}\]</span> 其中，<span class="math inline">\(B_1, B_2 \cdots B_n\)</span>表示对一个样本空间的分割，也就是 <span class="math inline">\(B_1, B_2\cdots B_n\)</span> 是互不相容的。</p><h2 id="贝叶斯公式">贝叶斯公式</h2><p><strong>贝叶斯公式 </strong> 应该算是概率论中最重要的公式了，它可以帮助我们借助容易计算的概率去计算一些不那么容易计算的概率。其可以记作<span class="math display">\[P(B|A) = \frac{P(A|B)P(B)}{P(A)}\]</span> 更一般的表达式为 <span class="math display">\[p(B_i|A) = \frac{P(A|B_i)P(B_i)}{\sum_{j}{P(B_j)P(A|B_j)}}\]</span> 其中 <span class="math inline">\(i, j = 1, 2 \cdotsn\)</span>，<span class="math inline">\(B_1, B_2 \cdots B_n\)</span>表示对一个样本空间的分割。</p><h2 id="独立性">独立性</h2><p><strong>独立性 </strong> 表示两个事件之间不是相互影响的，就称作这两个事件是 <strong> 相互独立 </strong> 的，如果有多个事件，当多个事件之间两两相互独立，才能称这些事件相互独立。如果两个事件是相互独立的，那么他们同时发生的概率可以直接由各自发生的概率相乘得到，记作<span class="math inline">\(P(AB)=P(A)P(B)\)</span>。</p><h2 id="马尔可夫性质">马尔可夫性质</h2><p><strong>马尔可夫性质 </strong> 也是机器学习中常用到的基本概念之一，它表示，一个随机过程的状态只跟当前状态有关，而跟过往的所有的状态都无关。用数学公式表达为<span class="math display">\[P(B_{n+1}|B_1, B_2 \cdots B_n) = P(B_{n+1} | B_n)\]</span></p><h1 id="概率分布">概率分布</h1><p>随机变量有 <strong> 连续随机变量 </strong> 和<strong>离散随机变量 </strong> 之分，那么相应的，用随机变量的 <strong> 分布函数 </strong> 来描述随机变量在所有取值上的概率，也有 <strong> 连续分布 </strong> 和<strong>离散分布 </strong> 之分。一般来说，分布函数表示的是概率，在整个自变量域内是单调的，而且还是非减的。针对连续的情况，更普遍的是用 <strong> 概率密度 </strong> 函数来描述概率的分布情况，对于概率密度的积分才得到概率本身（类比密度和质量的关系）。概率密度函数是非负的，而且在整个定义域上的积分之和一定等于1。在接下来的章节中，如果不加以特殊的说明，那么都是针对连续的情况而言。</p><h2 id="常用的分布">常用的分布</h2><p>在机器学习中，一些复杂的分布会使用一些简单的同时性质比较好的分布组合而成，因此，我们需要了解一些常用的简单的分布，其中最常见的应当是高斯分布了。</p><h3 id="高斯分布">高斯分布</h3><p><strong>高斯分布 </strong> 又叫做 <strong> 正太分布</strong>，记作 <spanclass="math inline">\(X \sim N(\mu, \sigma^2)\)</span>，也可以写成 <spanclass="math inline">\(p(x) \sim N(\mu, \sigma^2)\)</span>，其中 <spanclass="math inline">\(X\)</span> 表示随机变量，<spanclass="math inline">\(p(x)\)</span> 表示概率密度函数，其公式为 <spanclass="math display">\[p(x) = \frac{1}{\sqrt{2\pi\sigma^2}}\exp{\frac{-(x - \mu)^2}{2\sigma^2}}\]</span> 其中，<span class="math inline">\(\mu\)</span> 表示均值，<spanclass="math inline">\(\sigma\)</span>为方差。<strong>标准高斯分布 </strong> 的参数为 <spanclass="math inline">\(\mu = 0\)</span>，<spanclass="math inline">\(\sigma =1\)</span>。高斯分布很好的性质，比如任意高斯分布可以由一个标准的高斯分布得到，记作<span class="math inline">\(p(x) \sim N(0,1)\)</span>，这个性质可是使得随机采样可以参与梯度下降的优化算法，是随机优化算法的基本用法之一。高斯分布的68.27% 的样本在平均值左右的一个标准差的范围内，95.45%的样本在平均值左右的两个标准差的范围内，而 99.73%的样本都分布在平均值左右的三个标准差的范围内。高斯分布能够对现实中很多问题进行建模，当问题非常复杂的时候，还能够使用不同的高斯分布组合成复杂的 <strong> 混合高斯分布 </strong> 来描述，其中每个组成部分之间的概率表示可以为均匀分布或者自定义的其他分布。</p><h3 id="其他常用分布">其他常用分布</h3><p>其他常见的分布有 <strong> 均匀分布</strong>，概率密度函数的数学表达为<span class="math display">\[p(x) = \left\{\begin{aligned}  &amp;\frac{1}{b-a} \qquad  a \leq x \leq b \\  &amp;0 \qquad \qquad other  \end{aligned}    \right.\]</span> 其他的还是有泊松分布，几何分布等等。</p><h2 id="概率分布的数学特征">概率分布的数学特征</h2><h3 id="期望">期望</h3><p><strong>期望 </strong> 的定义是随机分布的加权平均值，可以写作 <spanclass="math display">\[E(X) = \mathbb{E}_{p(x)}(\cdot) = \int_{-\infty}^{＋\infty}xp(x) \ dx\]</span> 其中 <span class="math inline">\(\cdot\)</span>表示常数，也就是求的是本身的期望，如果替换成函数 <spanclass="math inline">\(g(x)\)</span>则表示在这个函数下的期望，在积分中需要乘上这个函数的值，比如 <spanclass="math display">\[\mathbb{E}_{p(x)}(g(x)) = \int_{-\infty}^{+\infty}g(x)p(x) \ dx\]</span> 严格来说，<span class="math inline">\(g(x)\)</span>还需要满足处处可导、单调等一些好的数学性质，这里不做专门展开了，证明也不详细介绍了。如果这个积分不收敛，那么可以说期望不存在。</p><h3 id="方差">方差</h3><p><strong>方差 </strong> 表示的是随机分布偏离均值的程度，或者说是波动的大小。可以写作<span class="math display">\[Var(X) = \int_{-\infty}^{+\infty}(x - \mathbb{E}_{p(x)})^2p(x) \ dx\]</span> 方差有一个更加实用的性质是 <span class="math display">\[Var(X) = E(X^2) - (E(X)^2)\]</span> “平方的期望减去期望的平方”，可以在各种场合快速计算方差。</p><h3 id="多维随机分布">多维随机分布</h3><p>多维随机分布简单来说就是样本空间的维度扩升到了高维，于是随机变量成为了 <strong> 联合随机变量 </strong> 密度函数成为了 <strong> 联合分布函数 </strong>，表示每一维的随机事件一起发生的概率，在连续分布中，使用<strong> 联合密度函数 </strong> 刻画，一般来说使用向量的方式记录，如<span class="math inline">\(p(\boldsymbol{x})\)</span>，加粗的 <spanclass="math inline">\(\boldsymbol{x}\)</span>表示向量。通过联合密度函数，求联合分布函数，当然也是使用多重积分进行的。最常见的有二维联合分布，<spanclass="math inline">\(p(\boldsymbol{x},\boldsymbol{y})\)</span>，在计算机视觉里面很常用，比如使用二维高斯分布作滤波器进行滤波操作等等。如果固定其他维度，对于某一个维度进行积分，那么表示这个 <strong> 边缘分布</strong>，主要关注的就是对于某一个随机变量的分布。</p><h3 id="协方差">协方差</h3><p>在二维随机分布中还有一个重要的概念，<strong>协方差</strong>。协方差表示两个分量之间的相关性，定义如下<span class="math display">\[Cov(X,Y) = E[(X - E(X))(Y - E(Y))]\]</span> 如果为 0，则表示不相关，大于 0，是正相关，小于0，是负相关。由协方差还可以引出 <strong> 相关系数</strong>，定义如下 <spanclass="math display">\[Corr(X,Y) = \frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}\]</span>当然，在刻画两个变量的相关性的时候，还有更加丰富的方法，比如信息论中的互信息等，在下面会讲到。</p><h2 id="jensen- 不等式">Jensen 不等式</h2><p>正在写...</p><!--## Jensen 不等式# 大数定律和中心极限定理## 大数定律## 中心极限定理# 参数估计## 概率密度估计## 极大似然估计# 随机算法## 采样算法## 遗传算法## 蒙特卡洛算法# 信息论## 熵## 交叉熵## KL 散度 -->]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;引言&quot;&gt;引言&lt;/h1&gt;
&lt;p&gt;不确定性可以说是在用数学工具对世界进行建模和认知的时候不可回避的问题，也是机器学习中的一个最基本的概念。于是，我们需要对这种不确定性进行量化和计算，而概率论能够为此提供一个合理的框架。所以，概率论是机器学习中最重要的基础理论之一，这也是本文要详细梳理概率论的基础知识的出发点。如果再辅之以其他工具如决策论、线性代数、微积分等，还能够在让我们构建世界观的同时，有切实可用的方法论。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://zrzfh.github.io/Zlog/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://zrzfh.github.io/Zlog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="不确定性" scheme="https://zrzfh.github.io/Zlog/tags/%E4%B8%8D%E7%A1%AE%E5%AE%9A%E6%80%A7/"/>
    
    <category term="模式识别" scheme="https://zrzfh.github.io/Zlog/tags/%E6%A8%A1%E5%BC%8F%E8%AF%86%E5%88%AB/"/>
    
    <category term="概率论" scheme="https://zrzfh.github.io/Zlog/tags/%E6%A6%82%E7%8E%87%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu 自定义路径下安装 SLEPc/PETSc 以及 BLAS/LAPACK 科学计算库</title>
    <link href="https://zrzfh.github.io/Zlog/slepc/"/>
    <id>https://zrzfh.github.io/Zlog/slepc/</id>
    <published>2023-03-24T05:50:27.000Z</published>
    <updated>2023-03-28T09:33:48.974Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言">引言</h1><p>最近在计算矩阵特征值的问题上，用到了 SLEPc（Scalable Library forEigenvalue Problem Computations），SLEPc可用于超大稀疏矩阵特征值的快速并行计算，也可以用于其他 SVD分解等常用矩阵计算。SLEPc 的安装依赖于其他通用科学计算库，比如PETSc，BLAS/LAPACK等，环境配置稍显复杂，因此，记录环境配置过程，以备后用。</p><span id="more"></span><h1 id="依赖关系">依赖关系</h1><p>SLEPc 是一个开源项目，可以在这里找到 <ahref="https://github.com/firedrakeproject/slepc/">https://github.com/firedrakeproject/slepc/</a>，有非常详细的使用说明（documentation），使用友好。SLEPc 依赖于PETSc，而 PETSc 依赖于 BLAS/LAPACK，因此，我们需要一一安装依赖项。</p><h1 id="blaslapack">BLAS/LAPACK</h1><p>BLAS（Basic Linear AlgebraSubprograms）定义了一系列矩阵、向量之间的基础运算的接口标准（API），Netlib实现了 BLAS 的这些接口，得到的库也叫 BLAS。以 BLAS 为基础，Netlib增加了更多高级的矩阵、向量运算，如分解、求逆、特征值等，并且实现了这些高级接口，于是有了LAPACK（Linear Algebra PackAage）。这两个库都是用 Fortran语言开发的（另外插一句，CBLAS 和 CLAPACK 是 BLAS 和 LAPACK 的 C语言接口）。</p><p>默认安装方式 <a href="#refer-anchor-1"><sup>[1]</sup></a>为（没有试过... 应该不会有什么问题...） <figure class="highlight q"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-<span class="built_in">get</span> install libblas-<span class="built_in">dev</span></span><br><span class="line">sudo apt-<span class="built_in">get</span> install liblapack-<span class="built_in">dev</span></span><br></pre></td></tr></table></figure> 默认位置在<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>libblas.a </span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>libblas.so </span><br><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/lib/</span>libblas.a</span><br><span class="line"></span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>liblapack.so </span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>liblapack.a</span><br><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/lib/</span>liblapack.a</span><br></pre></td></tr></table></figure></p><p>因为我需要安装在自定义路径中，所以下面进行一些自定义配置，如果不需要自定义路径，可以直接跳到<a href="#title-anchor-PETSc">下一节</a>。</p><h2 id="安装-fortran-语言的编译器-gfortran">安装 Fortran 语言的编译器gfortran</h2><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-<span class="built_in">get</span> install gfortran</span><br></pre></td></tr></table></figure><h2 id="安装-fftw-2">安装 FFTW <ahref="#refer-anchor-2"><sup>[2]</sup></a></h2><p><strong>i. 下载 FFTW</strong></p><p><ahref="http://www.fftw.org/download.html">http://www.fftw.org/download.html</a></p><p><strong>ii. 安装 FFTW</strong> <figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf fftw-3.3.10.tar.gz</span><br><span class="line"><span class="keyword">cd</span> fftw-3.3.10/</span><br><span class="line"><span class="comment"># 下面尽可能多的使用了指令集优化，不需要的化可以去掉相应的选项 </span></span><br><span class="line"><span class="comment"># cat /proc/cpuinfo 可以查看 cpu 支持的指令集 </span></span><br><span class="line"><span class="string">./configure</span> <span class="params">--prefix=/your/path/to/install</span> <span class="params">--enable-shared</span> <span class="params">--enable-static</span> <span class="params">--enable-single</span> <span class="params">--enable-sse</span> <span class="params">--enable-sse2</span> <span class="params">--enable-avx</span> <span class="params">--enable-avx2</span> <span class="params">--enable-fma</span> <span class="params">--enable-mpi</span> <span class="params">--enable-threads</span> <span class="params">--enable-openmp</span> </span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure><!-- * 如果 prefix 所指定的安装目录下的目录结构和自定义工程外部依赖路径下的自定义结构不一样，可以将安装目录下的 `include` 路径下的所有文件和 `lib` 路径下的所有文件分别拷贝到自定义工程外部依赖路径中的对应位置。 --></p><!-- ./configure --prefix=/opt/hmi_depends/algorithm_depends/fftw --enable-shared --enable-static --enable-single --enable-sse --enable-sse2 --enable-avx --enable-avx2 --enable-fma --enable-mpi --enable-threads --enable-openmp  --><h2 id="安装-blaslapack-2">安装 BLAS/LAPACK <ahref="#refer-anchor-2"><sup>[2]</sup></a></h2><p><strong>i. 确保 cmake 和 gfortran 已经安装 </strong></p><p><strong>ii. 下载 LAPACK</strong></p><p><ahref="https://netlib.org/lapack/">https://netlib.org/lapack/</a></p><p>幸运的是 LAPACK 中已经包含了 BLAS，所以不用重复下载。</p><p><strong>iii. 安装 LAPACK</strong></p><p>解压 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">tar</span> -zxvf lapack-<span class="number">3</span>.<span class="number">11</span>.tar.gz</span><br><span class="line"><span class="attribute">cd</span> lapack-<span class="number">3</span>.<span class="number">11</span></span><br></pre></td></tr></table></figure> 解压之后，它里面会含有 BLAS，CBLAS，LAPACKE等文件夹。新建 <code>make.inc</code> 文件 <figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cp</span> <span class="keyword">make</span>.inc.example <span class="keyword">make</span>.inc</span><br></pre></td></tr></table></figure> 如果是使用gfortran，则无须更改 <code>make.inc</code>里的内容，否则需要根据系统环境和编译器修改文件里对应的选项。</p><p>LAPACK 依赖 BLAS，在编译 LAPACK 前需要编译 BLAS包，而默认并不编译，因此，需要修改一下 <code>makefile</code><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">gedit</span> Makefile</span><br><span class="line"><span class="comment"># or </span></span><br><span class="line"><span class="comment"># vim Makefile</span></span><br></pre></td></tr></table></figure> 将第 <em>12~13</em> 行 <figure class="highlight crystal"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">lib</span>: <span class="title">lapacklib</span> <span class="title">tmglib</span></span></span><br><span class="line"><span class="comment">#lib: blaslib variants lapacklib tmglib</span></span><br></pre></td></tr></table></figure> 修改为 <figure class="highlight avrasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#lib: lapacklib tmglib</span></span><br><span class="line"><span class="symbol">lib:</span> blaslib variants lapacklib tmglib</span><br></pre></td></tr></table></figure>然后，进行编译 <figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">make</span></span><br></pre></td></tr></table></figure> <strong>【重要】</strong> 接下来，进入<code>LAPACKE</code> 目录并再次编译 <figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> LAPACKE</span><br><span class="line"><span class="keyword">make</span></span><br></pre></td></tr></table></figure> 在<code>lapack-3.11</code>目录下生成如下四个静态库，<code>liblapack.a, liblapacke.a, librefblas.a, libtmglib.a</code>则表示编译成功，将这四个静态库拷贝到自定义路径下的 <code>lib</code>路径，同时将 <code>LAPACKE/include</code>目录下的头文件拷贝到自定义路径下的 <code>include</code> 目录。</p><h1 id="安装-mpich">安装 MPICH</h1><p>PETSc 还依赖于 MPICH。</p><p><strong>i. 下载 MPICH</strong></p><p><ahref="https://www.mpich.org/downloads/">https://www.mpich.org/downloads/</a></p><p><strong>ii. 安装 MPICH</strong></p><p>一般情况使用默认安装模式就可以了，如果需要自定义安装，可以查看 <ahref="https://github.com/pmodels/mpich">这里</a>。以下为默认安装的方式。</p><p>解压 <figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">tar</span> -zxvf mpich-<span class="number">4</span>.<span class="number">1</span>.<span class="number">1</span>.tar.gz</span><br><span class="line"><span class="attribute">cd</span> mpich-<span class="number">4</span>.<span class="number">1</span>.<span class="number">1</span></span><br></pre></td></tr></table></figure> 编译 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/your/path/to/install 2&gt;&amp;1 | <span class="built_in">tee</span> c.txt</span><br><span class="line">make 2&gt;&amp;1 | <span class="built_in">tee</span> m.txt</span><br><span class="line">make install 2&gt;&amp;1 | <span class="built_in">tee</span> mi.txt</span><br></pre></td></tr></table></figure> 添加环境变量，打开<code>~/.bashrc</code>，添加如下命令并重新打开 shell <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH=<span class="regexp">/your/</span>path<span class="regexp">/to/i</span>nstall/bin:<span class="variable">$PATH</span>;</span><br></pre></td></tr></table></figure>检查，如果一切正常，下面两个命令会输出你指定的安装路径<code>/your/path/to/install/bin</code>。 <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">which</span> mpicc</span><br><span class="line"><span class="built_in">which</span> mpiexec</span><br></pre></td></tr></table></figure> 本地测试和结果<figure class="highlight vhdl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># <span class="keyword">to</span> run the CPI example <span class="keyword">with</span> <span class="symbol">&#x27;n</span>&#x27; processes <span class="keyword">on</span> your local machine</span><br><span class="line">mpiexec -n &lt;number&gt; ./examples/cpi</span><br><span class="line"></span><br><span class="line"># <span class="keyword">if</span> successfully installed, the outout will like this:</span><br><span class="line"># <span class="keyword">Process</span> <span class="number">0</span> <span class="keyword">of</span> <span class="number">2</span> <span class="keyword">is</span> <span class="keyword">on</span> adt</span><br><span class="line"># <span class="keyword">Process</span> <span class="number">1</span> <span class="keyword">of</span> <span class="number">2</span> <span class="keyword">is</span> <span class="keyword">on</span> adt</span><br><span class="line"># pi <span class="keyword">is</span> approximately <span class="number">3.1415926544231318</span>, <span class="literal">Error</span> <span class="keyword">is</span> <span class="number">0.0000000008333387</span></span><br><span class="line"># wall clock <span class="built_in">time</span> = <span class="number">0.001997</span></span><br></pre></td></tr></table></figure></p><h1 id="petsc-和-slepc-版本">PETSc 和 SLEPc 版本</h1><p>由于 SLEPc 是基于 PETSc 的，所以需要先安装 PETSc，再安装SLEPc。与此同时，要确保所下载的 PETSc 和 SLEPc 的版本能够符合 <ahref="https://slepc.upv.es/download/changes.htm">版本对应表</a>。</p><h1 id="安装-petsc">安装 PETSc</h1><div id="title-anchor-PETSc"></div><p><strong>i. 下载 PETSc</strong></p><p><ahref="https://petsc.org/release/install/download/">https://petsc.org/release/install/download/</a></p><p><strong>ii. 安装 PETSc</strong> <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf petsc-<span class="number">3.18</span>.<span class="number">5</span>.tar.gz</span><br><span class="line">cd petsc-<span class="number">3.18</span>.<span class="number">5</span></span><br><span class="line">.<span class="regexp">/configure --with-shared-libraries=0 --with-blas-lib=/y</span>our<span class="regexp">/path/</span>to<span class="regexp">/librefblas.a --with-lapack-lib=/y</span>our<span class="regexp">/path/</span>to<span class="regexp">/liblapack.a --with-mpi-dir=/y</span>our<span class="regexp">/path/</span>to/mpi</span><br><span class="line">make check all</span><br></pre></td></tr></table></figure> 需要使用 PETSc 库，将<code>include</code> 目录下的所有文件拷贝到安装目录 <code>include</code>下指定位置，同时将 <code>arch-linux-c-debug/include</code>目录下的所有头文件拷贝到安装目录 <code>include</code> 下指定位置，将<code>arch-linux-c-debug/lib/libpetsc.a</code> 拷贝到安装目录<code>lib</code> 下指定位置。</p><!-- ./configure --prefix=/opt/hmi_depends/algorithm_depends --with-shared-libraries=0 --with-blas-lib=/opt/hmi_depends/algorithm_depends/libs/lapack/librefblas.a --with-lapack-lib=/opt/hmi_depends/algorithm_depends/libs/lapack/liblapack.a --with-mpi-dir=/opt/hmi_depends/mpich --><h1 id="安装-slepc">安装 SLEPc</h1><p><strong>i. 下载 SLEPc</strong></p><p><ahref="https://slepc.upv.es/download/">https://slepc.upv.es/download/</a></p><p><strong>ii. 安装 SLEPc</strong> <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf slepc-3.18.3.tar.gz</span><br><span class="line">cd slepc-3.18.3</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">PETSC_DIR</span>=/path/to/petsc-3.18.5  # 此处应为 PETSc 解压并且编译过的路径，如我这里为 petsc-3.18.5 的绝对路径 </span><br><span class="line"><span class="built_in">export</span> <span class="attribute">PETSC_ARCH</span>=arch/of/petsc  # 此处应为 PETSc 编译时确定的当前编译版本的库的绝对路径，可以在 petsc-3.18.5 路径下找到 arch 开头的文件夹，如我这里为 arch-linux-c-<span class="built_in">debug</span></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">SLEPC_DIR</span>=/path/to/slepc-3.18.3  # 此处应为解压的 SLEPc 的路径 </span><br><span class="line"></span><br><span class="line">./configure</span><br><span class="line">make check all</span><br></pre></td></tr></table></figure> 最后将<code>include</code> 目录下的所有文件拷贝到安装目录 <code>include</code>下指定位置，<strong>【重要】</strong> 同时，将<code>arch-linux-c-debug/include/slepcconf.h</code> 拷贝到安装目录<code>include</code> 下指定位置。将<code>arch-linux-c-debug/lib/libslepc.a</code> 拷贝到安装目录<code>lib</code> 下指定位置。</p><!-- export PETSC_DIR=/home/adt/slepc/petsc-3.18.5export PETSC_ARCH=arch-linux-c-debugexport SLEPC_DIR=/home/adt/slepc/slepc-3.18.3  --><h1 id="可能遇到的问题">可能遇到的问题</h1><p>在使用 SLEPc 时，编译工程的过程中，需要添加的头文件路径有<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">...<span class="regexp">/mpich/i</span>nclude</span><br><span class="line">...<span class="regexp">/include/</span>petsc</span><br><span class="line">...<span class="regexp">/include/</span>slepc</span><br><span class="line">...<span class="regexp">/include/</span>fftw</span><br><span class="line">...<span class="regexp">/include/</span>lapack</span><br><span class="line"></span><br></pre></td></tr></table></figure> 需要链接的库有 <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">libslepc<span class="selector-class">.a</span></span><br><span class="line">libpetsc<span class="selector-class">.a</span></span><br><span class="line">libmpi<span class="selector-class">.a</span></span><br><span class="line">libmpicxx<span class="selector-class">.a</span></span><br><span class="line">libmpifort<span class="selector-class">.a</span></span><br><span class="line">liblapack<span class="selector-class">.a</span></span><br><span class="line">liblapacke<span class="selector-class">.a</span></span><br><span class="line">librefblas<span class="selector-class">.a</span></span><br><span class="line">libtmglib<span class="selector-class">.a</span></span><br><span class="line">libfftw3f<span class="selector-class">.a</span></span><br><span class="line">libfftw3f_mpi<span class="selector-class">.a</span></span><br><span class="line">libfftw3f_omp<span class="selector-class">.a</span></span><br><span class="line">libfftw3f_threads.a</span><br></pre></td></tr></table></figure></p><p>如果遇到了 <code>undefined reference to MPI_XXXX</code>的错误，还必须添加 OPENMPI 的头文件和库 <ahref="#refer-anchor-3"><sup>[3]</sup></a> <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加头文件路径（或者你的 openmpi 安装路径）</span></span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/openmpi/i</span>nclude</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加库路径（或者你的 openmpi 安装路径）</span></span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/openmpi/</span>lib</span><br><span class="line"><span class="comment"># 链接选项 </span></span><br><span class="line">-lmpi</span><br></pre></td></tr></table></figure> 如果没有安装OPENMPI 的话，需要安装一下，使用<code>sudo apt-get install openmpi</code>，但是需要注意版本。</p><p>如果遇到了<code>undefined reference to symbol 'udev_device_unref@@LIBUDEV_183'</code>的问题，需要添加 <code>libudev.so</code>。用 <code>locate libudev</code>找到路径，然后添加库路径 <figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 路径 </span></span><br><span class="line"><span class="regexp">/usr/</span>lib/x86_64-linux-gnu</span><br><span class="line"><span class="comment"># 链接选项 </span></span><br><span class="line">-ludev</span><br></pre></td></tr></table></figure></p><p>如果遇到了<code>undefined reference to symbol '__atomic_fetch_xor_16@@LIBATOMIC_1.0'</code>，需要添加<figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 链接选项 </span></span><br><span class="line"><span class="literal">-</span>latomic</span><br></pre></td></tr></table></figure></p><p>如果遇到了<code>undefined reference to '_gfortran_concat_string'</code>，需要添加<figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 链接选项 </span></span><br><span class="line"><span class="literal">-</span>lgfortran</span><br></pre></td></tr></table></figure></p><p>如果遇到了<code>undefined reference to XSetForeground (Maybe Some Drawing Functions)</code>，需要添加<figure class="highlight ldif"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 链接选项 </span></span><br><span class="line"><span class="literal">-</span>lX11</span><br></pre></td></tr></table></figure></p><h1 id="参考">参考</h1><div id="refer-anchor-1"></div><ul><li>[1] <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NDA5NTkyODcv">UbuntuBLAS/LAPACK 安装<i class="fa fa-external-link-alt"></i></span><div id="refer-anchor-2"></div></li><li>[2] <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYmFieWNsYXNzL3AvMTYzNTg1ODkuaHRtbA==">非ROOT 路径安装 BLAS/LAPACK<i class="fa fa-external-link-alt"></i></span><div id="refer-anchor-3"></div></li><li>[3] <ahref="https://blog.csdn.net/thj_2017720/article/details/118528324">undefinedreference to MPI_Init 解决办法</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;引言&quot;&gt;引言&lt;/h1&gt;
&lt;p&gt;最近在计算矩阵特征值的问题上，用到了 SLEPc（Scalable Library for
Eigenvalue Problem Computations），SLEPc
可用于超大稀疏矩阵特征值的快速并行计算，也可以用于其他 SVD
分解等常用矩阵计算。SLEPc 的安装依赖于其他通用科学计算库，比如
PETSc，BLAS/LAPACK
等，环境配置稍显复杂，因此，记录环境配置过程，以备后用。&lt;/p&gt;</summary>
    
    
    
    <category term="环境配置" scheme="https://zrzfh.github.io/Zlog/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
    
    <category term="Ubuntu" scheme="https://zrzfh.github.io/Zlog/tags/Ubuntu/"/>
    
    <category term="BLAS/LAPACK" scheme="https://zrzfh.github.io/Zlog/tags/BLAS-LAPACK/"/>
    
    <category term="PETSc" scheme="https://zrzfh.github.io/Zlog/tags/PETSc/"/>
    
    <category term="SLEPc" scheme="https://zrzfh.github.io/Zlog/tags/SLEPc/"/>
    
    <category term="快速矩阵计算" scheme="https://zrzfh.github.io/Zlog/tags/%E5%BF%AB%E9%80%9F%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97/"/>
    
    <category term="科学计算包" scheme="https://zrzfh.github.io/Zlog/tags/%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%8C%85/"/>
    
  </entry>
  
  <entry>
    <title>Invariant Information Clustering (IIC) 无监督的图像分类和分割</title>
    <link href="https://zrzfh.github.io/Zlog/IIC/"/>
    <id>https://zrzfh.github.io/Zlog/IIC/</id>
    <published>2023-03-10T02:07:52.000Z</published>
    <updated>2023-03-15T06:56:46.250Z</updated>
    
    <content type="html"><![CDATA[<h1 id="引言">引言</h1><p>2019 年，牛津大学提出了一种无监督，不依赖标签的聚类方法：InvariantInformation Clustering (IIC)，即根据给定数据对（DataPair）之间的互信息（Mutual Information,MI）提供端到端的、无标签的、无监督的方式训练神经网络，使其能够直接输出类别标签，从而实现聚类。</p><span id="more"></span><h1 id="原理方法">原理方法</h1><p>IIC建立在一个基本想法上，将单条数据经过简单并且不涉及材料本身畸变的仿射变化后，在变化前后的数据对中，同一个物体的描述应该（或者说必须）是一致的，当然，这里不包括物体上具体的细节。如果定义一个函数映射，将数据映射到某个空间（比如类别），那么只要通过优化，使得同一数据对在映射空间的各自输出能够保持一致就行了。</p><h2 id="问题思路">问题思路</h2><p>设 <span class="math inline">\(x, x^{\prime} \in \mathcal{X}\)</span> 是一对数据对，服从分布 <span class="math inline">\(p(x,x^\prime)\)</span>, 即 <span class="math inline">\(x, x^{\prime} \simp (x, x^{\prime})\)</span>，IIC 的目的是学习得到一个映射 <spanclass="math inline">\(\Phi: \mathcal {X} \rightarrow \mathcal{Y}\)</span>，能够保持 <span class="math inline">\(x,x^{\prime}\)</span>两者之间共性（如含有的同一个物体），而忽略特定的细节（如物体上的具体细节信息），其中<span class="math inline">\(\mathcal {X}\)</span> 是样本集合，<spanclass="math inline">\(\mathcal {Y} = \{1, \dots,C\}\)</span>是有限集合。用数学语言描述，<span class="math inline">\(\Phi\)</span>可以通过 <strong>​最大化数据对在映射空间的互信息（MI）​</strong>得到，用公式表示为 <span class="math display">\[ \mathop{max}\limits_{\Phi} \ I (\Phi (x), \Phi (x^{\prime})) \]</span>通常来说，<span class="math inline">\(I (x)\)</span>中已经包含了熵（Entropy），可以避免模型退化（Degeneracy），可以认为，含有熵的模型不至于直接收缩到某一个点上。此处，<spanclass="math inline">\(\Phi\)</span> 可以是一个神经网络，论文中使用“瓶颈（Bottleneck）” 结构，可用于忽略特定的细节。</p><h2 id="数学定义">数学定义</h2><p>互信息（MI）是信息论中的基本概念，与之相对的还有自信息（Self-Information）。而熵（Entropy）和相对熵（RelativeEntropy,RE）是与之相关且不可或缺的重要基础概念之一。在使用之前，我们来简单回顾一下这些基础概念。</p><p>为了方便，下文约定：用 <span class="math inline">\(p (x)\)</span>专门指代随机变量 <span class="math inline">\(X:\mathcal {X} \rightarrow\mathbb {R}\)</span> 的概率密度函数，<spanclass="math inline">\(\mathcal {X}\)</span> 为样本空间，且 <spanclass="math inline">\(x \in \mathcal{X}\)</span>。以此类推，指代同一个随机变量的相关参数或者变量，会使用同一个字母的不同字体表示。例如需要注意到<span class="math inline">\(p (x)\)</span> 和 <spanclass="math inline">\(p (y)\)</span> 分别指代两个随机变量 <spanclass="math inline">\(X\)</span> 和 <spanclass="math inline">\(Y\)</span>的概率密度函数。而且，在本文中对于离散随机变量和连续随机变量不加以区分，公式中都使用离散随机变量表示。如果使用连续随机变量，那么需要把求和符号替换成积分符号。</p><h3 id="熵entropy">熵（Entropy）</h3><p>在信息论中，熵（Entropy）是用来测量随机变量的不确定度的，设变量 <spanclass="math inline">\(x\)</span> 服从分布 <span class="math inline">\(p(x)\)</span>, 记作 <span class="math inline">\(x \sim p(x)\)</span>，那么随机变量 <span class="math inline">\(X\)</span>的熵（Entropy）<span class="math inline">\(H (X)\)</span> 定义为 <spanclass="math display">\[ H (X) = - \sum_{x \in \mathcal {X}} p (x) \ log\ p (x) \]</span></p><p>当然，如果有一对随机变量服从联合分布，记作 <spanclass="math inline">\(x, y \sim ~ p (x,y)\)</span>，那么联合熵（JointEntropy） <span class="math inline">\(H (X,Y)\)</span> 显然可以写作<span class="math display">\[ H (X, Y) = - \sum_{x \in \mathcal {X}}\sum_{y \in \mathcal {Y}} p (x, y) \ log \ p (x,y) \]</span></p><p>这一对随机变量的条件熵（Conditional Entropy）<spanclass="math inline">\(H (Y|X)\)</span> 可以写成 <spanclass="math display">\[\begin {split}H (Y|X) &amp;= \sum_{x \in \mathcal {X}} p (x) \ H (Y|X=x) \\&amp;= - \sum_{x \in \mathcal {X}} p (x) \sum_{y \in \mathcal {Y}} p(y|x) \ log \ p (y|x) \\&amp;= - \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x, y) \log \ p (y|x)\end {split}\]</span></p><p>其中，有个常用的定理链式法则（Chain Rule） <spanclass="math display">\[\begin {split}H (X, Y) &amp;= H (X) + H (Y|X) \\H (X, Y|Z) &amp;= H (X|Z) + H (Y|X, Z)\end {split}\]</span></p><h3 id="相对熵re">相对熵（RE）</h3><p>相对熵（RE）是用来测量两个分布之间的“距离”（或者称之为相似程度），也可称为 KL 散度（Kullback–LeiblerDivergence, KLD）。两个分布 <span class="math inline">\(p (x), q(x)\)</span> 之间的 KL 散度（KLD） 定义为 <span class="math display">\[\begin {equation}D_{KL}(p (x)||q (x)) = \sum_{x \in \mathcal {X}} p (x) log\frac {p(x)}{q (x)}\end {equation}\]</span></p><p>KL 散度（KLD）的几个小性质：</p><p>1、<span class="math inline">\(D_{KL}(p (x)||q (x)) \geq0\)</span>，</p><p>2、<span class="math inline">\(D_{KL}(p (x)||q (x)) =0\)</span>，当且仅当 <span class="math inline">\(p (x) = q(x)\)</span>，</p><p>3、<span class="math inline">\(D_{KL}(p (x)||q (x)) \neq D_{KL}(q(x)||p (x))\)</span>。</p><h3 id="互信息mi">互信息（MI）</h3><p>接下来给出互信息（MI）的定义。给定联合分布 <spanclass="math inline">\(p (x, y)\)</span> 和边缘分布 <spanclass="math inline">\(p (x), p (y)\)</span>，互信息（MI）<spanclass="math inline">\(I (X; Y)\)</span> 定义为 <spanclass="math display">\[\begin {equation}\begin {split}I (X; Y) &amp;= \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p(x, y) \ log \ \frac {p (x,y)}{p (x) p (y)}  \\&amp;= D_{KL}(p (x,y)||p (x) p (y))\end {split}\label {midef}\end {equation}\]</span> <span class="math inline">\(I (X;Y)\)</span>可以理解成联合分布 <span class="math inline">\(p (x,y)\)</span>与边缘分布乘积 <span class="math inline">\(p (x) p (y)\)</span> 之间的KL 散度（KLD）。通过观察，可以将公式 <span class="math inline">\(\eqref{midef}\)</span> 进一步变化得到 <span class="math display">\[\begin {equation}\begin {split}I (X; Y) &amp;= \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p(x, y) \ log \ \frac {p (x,y)}{p (x) p (y)}  \\&amp;= \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x, y) \log \ \frac {p (x|y)}{p (x)}  \\&amp;= - \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x, y) \log \ p (x) + \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x,y) \ log \ p (x|y)  \\&amp;= - \sum_{x \in \mathcal {X}} p (x) \ log \ p (x) - \left (-\sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x, y) \ log \ p(x|y) \right) \\&amp;= H (X) - H (X|Y)\end {split}\label {mitra}\end {equation}\]</span> 这就是互信息（MI）和熵（Entropy）之间的联系。</p><h3 id="自信息self-information">自信息（Self-Information）</h3><p>如果把公式 <span class="math inline">\(\eqref {mitra}\)</span> 中的<span class="math inline">\(Y\)</span> 随机变量替换成 <spanclass="math inline">\(X\)</span> 随机变量，就可以得到 <spanclass="math display">\[\begin {equation}I (X;X) =  H (X) - H (X|X) = H (X)\label {sidef}\end {equation}\]</span> 这被定义为自信息（Self-Information），从公式 <spanclass="math inline">\(\eqref {sidef}\)</span>来看，熵（Entropy）和自信息（Self-Information）在某种程度上是一致的。</p><h2 id="具体方式">具体方式</h2><p>论文考虑使用软聚类（soft clustering），因此将输出 <spanclass="math inline">\(\Phi (x) \in [0, 1]^C\)</span>表示成一个离散分布，即 <span class="math inline">\(p (z=c|x) = {\Phi}_c(x)\)</span>，于是一对变量 <span class="math inline">\(x,x^\prime\)</span> 的输出结果 <span class="math inline">\(z,z^\prime\)</span> 可以表示成一个联合分布： <span class="math display">\[P (z=c, z^\prime=c^\prime|x, x^\prime) = {\Phi}_c (x) \cdot {\Phi}_c(x^\prime)\]</span> 实际上，<span class="math inline">\(z, z^\prime\)</span>不是独立的，而且还是强相关的。在数据集（实际处理是batch）上进行边缘化得到一个联合分布 <spanclass="math inline">\(P\)</span>, <span class="math inline">\(P\)</span>使用矩阵表示，大小为 <span class="math inline">\([C \timesC]\)</span>，于是其中元素可以写成 <span class="math display">\[\begin {equation}P_{cc^\prime} = \frac {1}{n}\sum_{i=1}^{n}\Phi (x_i)\cdot\Phi({x_i}^\prime)^T\label {matdef}\end {equation}\]</span> 且一般来说将 <span class="math inline">\(P\)</span> 用 <spanclass="math inline">\((P+P^T)/2\)</span> 构造成一个对称矩阵。其中，<spanclass="math inline">\(P_c=P (z=c)\)</span> 和 <spanclass="math inline">\(P_{c^\prime}=P (z^\prime=c^\prime)\)</span>能够直接通过矩阵中相应的行或列累加得到。最终，得到互信息（MI）的表达式：<span class="math display">\[I (z,z^\prime) = I (P) = \sum_{c=1}^{C}\sum_{c^\prime=1}^{C}P_{cc^\prime} \cdot ln \ \frac {P_{cc^\prime}}{P_{c} P_{c^\prime}}\]</span> 作为目标函数（Objective Function）。</p><h3 id="图像聚类">图像聚类</h3><p>在图像聚类中，考虑对采样 <span class="math inline">\(x\)</span>进行随机的扰动（比如平移、旋转，灰度映射等）变化得到 <spanclass="math inline">\(x^\prime\)</span>，记作 <spanclass="math inline">\(x^\prime=gx\)</span>，因此将以上 <spanclass="math inline">\(x^\prime\)</span> 代替成随机扰动（变换）后的 <spanclass="math inline">\(gx\)</span> 即可。</p><h3 id="图像分割">图像分割</h3><p>在图像分割中，由于需要对每个像素都进行划分，所以要对图像进行分块（patch），并且要利用块之间的空间位置信息。于是，需要给目标函数（ObjectiveFunction）增加局部空间不变性（Local SpatialInvariance）。具体的，如果给定一张 RGB 图像 <spanclass="math inline">\(x\in \mathbb {R}^{3 \times H \times W}\)</span>,<span class="math inline">\(u \in \Omega = \{1, \ldots, H\} \times \{1,\ldots, W\}\)</span> 表示一个像素位置，<spanclass="math inline">\(x_u\)</span> 是以 <spanclass="math inline">\(u\)</span> 为中心的一个块（patch）。假设现存在一个<span class="math inline">\(t \in T \subset \mathbb {Z}^2\)</span>，使得<span class="math inline">\(u+t\)</span> 为 <spanclass="math inline">\(u\)</span> 的领域，那么可以构成一对数据 <spanclass="math inline">\(\Phi (x_u), \Phi(x_{u+t})\)</span>，而它们可以直接从 <span class="math inline">\(\eqref{matdef}\)</span>所表示的矩阵中按列读取，因为自始至终都只用了一个神经网络映射 <spanclass="math inline">\(\Phi\)</span>。</p><p>记 <span class="math inline">\(\Phi (x_u) = \Phi_u(x)\)</span>，那么它对应的另一个数据应为 <spanclass="math inline">\(\Phi_{g(u)}(gx)\)</span>，因为坐标也因为随机扰动已经变化了。如果以坐标变化前参考，那么可以写成<span class="math inline">\(\Phi_{g (u)}(gx) = {\big [ g^{-1} \Phi (gx)\big ]}_u\)</span>。因此，<span class="math inline">\(\Phi_u(x)\)</span> 和 <span class="math inline">\({\big [ g^{-1} \Phi (gx)\big ]}_u\)</span> 构成一对数据对，也就是说只要在 <spanclass="math inline">\(\Phi_u (gx)\)</span> 的基础上再进行一次 <spanclass="math inline">\(g^{-1}\)</span> 逆变换，就可以构成原 <spanclass="math inline">\(\Phi_u (x)\)</span>的数据对。于是，现在给出图像分割的目标函数： <spanclass="math display">\[\begin {equation}\begin {split}\frac {1}{|T|}\sum_{t \in T} I (\Phi_u (x);g^{-1}\Phi_u (gx)) &amp;=\frac {1}{|T|}\sum_{t \in T} I (P_t) \\&amp;= \frac {1}{|T|}\sum_{t \in T} I (\frac{1}{n|G||\Omega|}\sum_{i=1}^{n}\sum_{g \in G}\sum_{u \in \Omega}\Phi_u(x_i) \cdot \big [ g^{-1} \Phi (gx_i) \big ]^{T}_{u+t})\end {split}\label {sodef}\end {equation}\]</span> 其中，第一个求和符号表示对 <spanclass="math inline">\(i=1,\ldots,n\)</span> 个图像（实际指得是batch）进行求和，第二个求和符号表示对于任意的随机变化进行求和，第三个求和符号表示对每张图像中的块进行求和。论文原文中，把最后一个求和部分看成了Convolution（为什么？）。然后根据最大化目标函数，求解最优的 <spanclass="math inline">\(\Phi\)</span>。</p><h1 id="总结">总结</h1><p>IIC最大的优点之一应该就是避免了大量的数据标注问题，能够提供一个无监督的方式对图像进行语义级别的分割。作者很巧妙的使用了随机变换生成的数据对中两者的互信息（MI），似乎更像是一种“差分”的方式。其中，作者还提到该模型能够很好避免模型退化。论文的想法非常值得学习，对于不同分布的相似程度的评价以及映射函数，似乎还能有更好的优化，不知道增加一些惩罚项能否进一步增强模型能力，另外使用更强的映射转换模型（transformer）是否也能够进一步优化？</p><p>论文地址：<ahref="https://arxiv.org/abs/1807.06653">https://arxiv.org/abs/1807.06653</a><br />代码地址：<ahref="https://github.com/xu-ji/IIC">https://github.com/xu-ji/IIC</a><br />GitHub 上作者给出的代码用起来很不方便，还是以 python2 环境为主，仅支持GPU ... 挖个坑，优化一下代码的使用和环境配置...</p>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;引言&quot;&gt;引言&lt;/h1&gt;
&lt;p&gt;2019 年，牛津大学提出了一种无监督，不依赖标签的聚类方法：Invariant
Information Clustering (IIC)，即根据给定数据对（Data
Pair）之间的互信息（Mutual Information,
MI）提供端到端的、无标签的、无监督的方式训练神经网络，使其能够直接输出类别标签，从而实现聚类。&lt;/p&gt;</summary>
    
    
    
    <category term="论文笔记" scheme="https://zrzfh.github.io/Zlog/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="机器学习" scheme="https://zrzfh.github.io/Zlog/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="无监督学习" scheme="https://zrzfh.github.io/Zlog/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="深度学习" scheme="https://zrzfh.github.io/Zlog/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="图像分割" scheme="https://zrzfh.github.io/Zlog/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/"/>
    
    <category term="图像分类" scheme="https://zrzfh.github.io/Zlog/tags/%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>序</title>
    <link href="https://zrzfh.github.io/Zlog/%E5%BA%8F/"/>
    <id>https://zrzfh.github.io/Zlog/%E5%BA%8F/</id>
    <published>2023-03-08T01:56:08.000Z</published>
    <updated>2023-03-11T14:20:13.016Z</updated>
    
    <content type="html"><![CDATA[<p>不积跬步，无以至千里。 <span id="more"></span>学习很重要，思考很重要，整理同样也很重要。因此，本博客专门用于学习过程中的整理和记录，便于温故而知新。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;不积跬步，无以至千里。</summary>
    
    
    
    
  </entry>
  
</feed>
