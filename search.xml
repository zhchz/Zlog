<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Invariant Information Clustering (IIC) 无监督的图像分类和分割</title>
    <url>/Zlog/IIC/</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<p>2019 年，牛津大学提出了一种无监督，不依赖标签的聚类方法：Invariant
Information Clustering (IIC)，即根据给定数据对（Data
Pair）之间的互信息（Mutual Information,
MI）提供端到端的、无标签的、无监督的方式训练神经网络，使其能够直接输出类别标签，从而实现聚类。</p>
<span id="more"></span>
<h1 id="原理方法">原理方法</h1>
<p>IIC
建立在一个基本想法上，将单条数据经过简单并且不涉及材料本身畸变的仿射变化后，在变化前后的数据对中，同一个物体的描述应该（或者说必须）是一致的，当然，这里不包括物体上具体的细节。如果定义一个函数映射，将数据映射到某个空间（比如类别），那么只要通过优化，使得同一数据对在映射空间的各自输出能够保持一致就行了。</p>
<h2 id="问题思路">问题思路</h2>
<p>设 <span class="math inline">\(x, x^{\prime} \in \mathcal
{X}\)</span> 是一对数据对，服从分布 <span class="math inline">\(p
(x,x^\prime)\)</span>, 即 <span class="math inline">\(x, x^{\prime} \sim
p (x, x^{\prime})\)</span>，IIC 的目的是学习得到一个映射 <span
class="math inline">\(\Phi: \mathcal {X} \rightarrow \mathcal
{Y}\)</span>，能够保持 <span class="math inline">\(x,
x^{\prime}\)</span>
两者之间共性（如含有的同一个物体），而忽略特定的细节（如物体上的具体细节信息），其中
<span class="math inline">\(\mathcal {X}\)</span> 是样本集合，<span
class="math inline">\(\mathcal {Y} = \{1, \dots,C\}\)</span>
是有限集合。用数学语言描述，<span class="math inline">\(\Phi\)</span>
可以通过 <strong>​最大化数据对在映射空间的互信息（MI）​</strong>
得到，用公式表示为 <span class="math display">\[ \mathop
{max}\limits_{\Phi} \ I (\Phi (x), \Phi (x^{\prime})) \]</span>
通常来说，<span class="math inline">\(I (x)\)</span>
中已经包含了熵（Entropy），可以避免模型退化（Degeneracy），可以认为，含有熵的模型不至于直接收缩到某一个点上。此处，<span
class="math inline">\(\Phi\)</span> 可以是一个神经网络，论文中使用
“瓶颈（Bottleneck）” 结构，可用于忽略特定的细节。</p>
<h2 id="数学定义">数学定义</h2>
<p>互信息（MI）是信息论中的基本概念，与之相对的还有自信息（Self-Information）。而熵（Entropy）和相对熵（Relative
Entropy,
RE）是与之相关且不可或缺的重要基础概念之一。在使用之前，我们来简单回顾一下这些基础概念。</p>
<p>为了方便，下文约定：用 <span class="math inline">\(p (x)\)</span>
专门指代随机变量 <span class="math inline">\(X:\mathcal {X} \rightarrow
\mathbb {R}\)</span> 的概率密度函数，<span
class="math inline">\(\mathcal {X}\)</span> 为样本空间，且 <span
class="math inline">\(x \in \mathcal
{X}\)</span>。以此类推，指代同一个随机变量的相关参数或者变量，会使用同一个字母的不同字体表示。例如需要注意到
<span class="math inline">\(p (x)\)</span> 和 <span
class="math inline">\(p (y)\)</span> 分别指代两个随机变量 <span
class="math inline">\(X\)</span> 和 <span
class="math inline">\(Y\)</span>
的概率密度函数。而且，在本文中对于离散随机变量和连续随机变量不加以区分，公式中都使用离散随机变量表示。如果使用连续随机变量，那么需要把求和符号替换成积分符号。</p>
<h3 id="熵entropy">熵（Entropy）</h3>
<p>在信息论中，熵（Entropy）是用来测量随机变量的不确定度的，设变量 <span
class="math inline">\(x\)</span> 服从分布 <span class="math inline">\(p
(x)\)</span>, 记作 <span class="math inline">\(x \sim p
(x)\)</span>，那么随机变量 <span class="math inline">\(X\)</span>
的熵（Entropy）<span class="math inline">\(H (X)\)</span> 定义为 <span
class="math display">\[ H (X) = - \sum_{x \in \mathcal {X}} p (x) \ log
\ p (x) \]</span></p>
<p>当然，如果有一对随机变量服从联合分布，记作 <span
class="math inline">\(x, y \sim ~ p (x,y)\)</span>，那么联合熵（Joint
Entropy） <span class="math inline">\(H (X,Y)\)</span> 显然可以写作
<span class="math display">\[ H (X, Y) = - \sum_{x \in \mathcal {X}}
\sum_{y \in \mathcal {Y}} p (x, y) \ log \ p (x,y) \]</span></p>
<p>这一对随机变量的条件熵（Conditional Entropy）<span
class="math inline">\(H (Y|X)\)</span> 可以写成 <span
class="math display">\[
\begin {split}
H (Y|X) &amp;= \sum_{x \in \mathcal {X}} p (x) \ H (Y|X=x) \\
&amp;= - \sum_{x \in \mathcal {X}} p (x) \sum_{y \in \mathcal {Y}} p
(y|x) \ log \ p (y|x) \\
&amp;= - \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x, y) \
log \ p (y|x)
\end {split}
\]</span></p>
<p>其中，有个常用的定理链式法则（Chain Rule） <span
class="math display">\[
\begin {split}
H (X, Y) &amp;= H (X) + H (Y|X) \\
H (X, Y|Z) &amp;= H (X|Z) + H (Y|X, Z)
\end {split}
\]</span></p>
<h3 id="相对熵re">相对熵（RE）</h3>
<p>相对熵（RE）是用来测量两个分布之间的
“距离”（或者称之为相似程度），也可称为 KL 散度（Kullback–Leibler
Divergence, KLD）。两个分布 <span class="math inline">\(p (x), q
(x)\)</span> 之间的 KL 散度（KLD） 定义为 <span class="math display">\[
\begin {equation}
D_{KL}(p (x)||q (x)) = \sum_{x \in \mathcal {X}} p (x) log\frac {p
(x)}{q (x)}
\end {equation}
\]</span></p>
<p>KL 散度（KLD）的几个小性质：</p>
<p>1、<span class="math inline">\(D_{KL}(p (x)||q (x)) \geq
0\)</span>，</p>
<p>2、<span class="math inline">\(D_{KL}(p (x)||q (x)) =
0\)</span>，当且仅当 <span class="math inline">\(p (x) = q
(x)\)</span>，</p>
<p>3、<span class="math inline">\(D_{KL}(p (x)||q (x)) \neq D_{KL}(q
(x)||p (x))\)</span>。</p>
<h3 id="互信息mi">互信息（MI）</h3>
<p>接下来给出互信息（MI）的定义。给定联合分布 <span
class="math inline">\(p (x, y)\)</span> 和边缘分布 <span
class="math inline">\(p (x), p (y)\)</span>，互信息（MI）<span
class="math inline">\(I (X; Y)\)</span> 定义为 <span
class="math display">\[
\begin {equation}
\begin {split}
I (X; Y) &amp;= \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p
(x, y) \ log \ \frac {p (x,y)}{p (x) p (y)}  \\
&amp;= D_{KL}(p (x,y)||p (x) p (y))
\end {split}
\label {midef}
\end {equation}
\]</span> <span class="math inline">\(I (X;Y)\)</span>
可以理解成联合分布 <span class="math inline">\(p (x,y)\)</span>
与边缘分布乘积 <span class="math inline">\(p (x) p (y)\)</span> 之间的
KL 散度（KLD）。通过观察，可以将公式 <span class="math inline">\(\eqref
{midef}\)</span> 进一步变化得到 <span class="math display">\[
\begin {equation}
\begin {split}
I (X; Y) &amp;= \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p
(x, y) \ log \ \frac {p (x,y)}{p (x) p (y)}  \\
&amp;= \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x, y) \
log \ \frac {p (x|y)}{p (x)}  \\
&amp;= - \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x, y) \
log \ p (x) + \sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x,
y) \ log \ p (x|y)  \\
&amp;= - \sum_{x \in \mathcal {X}} p (x) \ log \ p (x) - \left (-
\sum_{x \in \mathcal {X}} \sum_{y \in \mathcal {Y}} p (x, y) \ log \ p
(x|y) \right) \\
&amp;= H (X) - H (X|Y)
\end {split}
\label {mitra}
\end {equation}
\]</span> 这就是互信息（MI）和熵（Entropy）之间的联系。</p>
<h3 id="自信息self-information">自信息（Self-Information）</h3>
<p>如果把公式 <span class="math inline">\(\eqref {mitra}\)</span> 中的
<span class="math inline">\(Y\)</span> 随机变量替换成 <span
class="math inline">\(X\)</span> 随机变量，就可以得到 <span
class="math display">\[
\begin {equation}
I (X;X) =  H (X) - H (X|X) = H (X)
\label {sidef}
\end {equation}
\]</span> 这被定义为自信息（Self-Information），从公式 <span
class="math inline">\(\eqref {sidef}\)</span>
来看，熵（Entropy）和自信息（Self-Information）在某种程度上是一致的。</p>
<h2 id="具体方式">具体方式</h2>
<p>论文考虑使用软聚类（soft clustering），因此将输出 <span
class="math inline">\(\Phi (x) \in [0, 1]^C\)</span>
表示成一个离散分布，即 <span class="math inline">\(p (z=c|x) = {\Phi}_c
(x)\)</span>，于是一对变量 <span class="math inline">\(x,
x^\prime\)</span> 的输出结果 <span class="math inline">\(z,
z^\prime\)</span> 可以表示成一个联合分布： <span class="math display">\[
P (z=c, z^\prime=c^\prime|x, x^\prime) = {\Phi}_c (x) \cdot {\Phi}_c
(x^\prime)
\]</span> 实际上，<span class="math inline">\(z, z^\prime\)</span>
不是独立的，而且还是强相关的。在数据集（实际处理是
batch）上进行边缘化得到一个联合分布 <span
class="math inline">\(P\)</span>, <span class="math inline">\(P\)</span>
使用矩阵表示，大小为 <span class="math inline">\([C \times
C]\)</span>，于是其中元素可以写成 <span class="math display">\[
\begin {equation}
P_{cc^\prime} = \frac {1}{n}\sum_{i=1}^{n}\Phi (x_i)\cdot\Phi
({x_i}^\prime)^T
\label {matdef}
\end {equation}
\]</span> 且一般来说将 <span class="math inline">\(P\)</span> 用 <span
class="math inline">\((P+P^T)/2\)</span> 构造成一个对称矩阵。其中，<span
class="math inline">\(P_c=P (z=c)\)</span> 和 <span
class="math inline">\(P_{c^\prime}=P (z^\prime=c^\prime)\)</span>
能够直接通过矩阵中相应的行或列累加得到。最终，得到互信息（MI）的表达式：
<span class="math display">\[
I (z,z^\prime) = I (P) = \sum_{c=1}^{C}\sum_{c^\prime=1}^{C}
P_{cc^\prime} \cdot ln \ \frac {P_{cc^\prime}}{P_{c} P_{c^\prime}}
\]</span> 作为目标函数（Objective Function）。</p>
<h3 id="图像聚类">图像聚类</h3>
<p>在图像聚类中，考虑对采样 <span class="math inline">\(x\)</span>
进行随机的扰动（比如平移、旋转，灰度映射等）变化得到 <span
class="math inline">\(x^\prime\)</span>，记作 <span
class="math inline">\(x^\prime=gx\)</span>，因此将以上 <span
class="math inline">\(x^\prime\)</span> 代替成随机扰动（变换）后的 <span
class="math inline">\(gx\)</span> 即可。</p>
<h3 id="图像分割">图像分割</h3>
<p>在图像分割中，由于需要对每个像素都进行划分，所以要对图像进行分块（patch），并且要利用块之间的空间位置信息。于是，需要给目标函数（Objective
Function）增加局部空间不变性（Local Spatial
Invariance）。具体的，如果给定一张 RGB 图像 <span
class="math inline">\(x\in \mathbb {R}^{3 \times H \times W}\)</span>,
<span class="math inline">\(u \in \Omega = \{1, \ldots, H\} \times \{1,
\ldots, W\}\)</span> 表示一个像素位置，<span
class="math inline">\(x_u\)</span> 是以 <span
class="math inline">\(u\)</span> 为中心的一个块（patch）。假设现存在一个
<span class="math inline">\(t \in T \subset \mathbb {Z}^2\)</span>，使得
<span class="math inline">\(u+t\)</span> 为 <span
class="math inline">\(u\)</span> 的领域，那么可以构成一对数据 <span
class="math inline">\(\Phi (x_u), \Phi
(x_{u+t})\)</span>，而它们可以直接从 <span class="math inline">\(\eqref
{matdef}\)</span>
所表示的矩阵中按列读取，因为自始至终都只用了一个神经网络映射 <span
class="math inline">\(\Phi\)</span>。</p>
<p>记 <span class="math inline">\(\Phi (x_u) = \Phi_u
(x)\)</span>，那么它对应的另一个数据应为 <span
class="math inline">\(\Phi_{g
(u)}(gx)\)</span>，因为坐标也因为随机扰动已经变化了。如果以坐标变化前参考，那么可以写成
<span class="math inline">\(\Phi_{g (u)}(gx) = {\big [ g^{-1} \Phi (gx)
\big ]}_u\)</span>。因此，<span class="math inline">\(\Phi_u
(x)\)</span> 和 <span class="math inline">\({\big [ g^{-1} \Phi (gx)
\big ]}_u\)</span> 构成一对数据对，也就是说只要在 <span
class="math inline">\(\Phi_u (gx)\)</span> 的基础上再进行一次 <span
class="math inline">\(g^{-1}\)</span> 逆变换，就可以构成原 <span
class="math inline">\(\Phi_u (x)\)</span>
的数据对。于是，现在给出图像分割的目标函数： <span
class="math display">\[
\begin {equation}
\begin {split}
\frac {1}{|T|}\sum_{t \in T} I (\Phi_u (x);g^{-1}\Phi_u (gx)) &amp;=
\frac {1}{|T|}\sum_{t \in T} I (P_t) \\
&amp;= \frac {1}{|T|}\sum_{t \in T} I (\frac
{1}{n|G||\Omega|}\sum_{i=1}^{n}\sum_{g \in G}\sum_{u \in \Omega}\Phi_u
(x_i) \cdot \big [ g^{-1} \Phi (gx_i) \big ]^{T}_{u+t})
\end {split}
\label {sodef}
\end {equation}
\]</span> 其中，第一个求和符号表示对 <span
class="math inline">\(i=1,\ldots,n\)</span> 个图像（实际指得是
batch）进行求和，第二个求和符号表示对于任意的随机变化进行求和，第三个求和符号表示对每张图像中的块进行求和。论文原文中，把最后一个求和部分看成了
Convolution（为什么？）。然后根据最大化目标函数，求解最优的 <span
class="math inline">\(\Phi\)</span>。</p>
<h1 id="总结">总结</h1>
<p>IIC
最大的优点之一应该就是避免了大量的数据标注问题，能够提供一个无监督的方式对图像进行语义级别的分割。作者很巧妙的使用了随机变换生成的数据对中两者的互信息（MI），似乎更像是一种
“差分”
的方式。其中，作者还提到该模型能够很好避免模型退化。论文的想法非常值得学习，对于不同分布的相似程度的评价以及映射函数，似乎还能有更好的优化，不知道增加一些惩罚项能否进一步增强模型能力，另外使用更强的映射转换模型（transformer）是否也能够进一步优化？</p>
<p>论文地址：<a
href="https://arxiv.org/abs/1807.06653">https://arxiv.org/abs/1807.06653</a><br />
代码地址：<a
href="https://github.com/xu-ji/IIC">https://github.com/xu-ji/IIC</a><br />
GitHub 上作者给出的代码用起来很不方便，还是以 python2 环境为主，仅支持
GPU ... 挖个坑，优化一下代码的使用和环境配置...</p>
]]></content>
      <categories>
        <category>论文笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>无监督学习</tag>
        <tag>深度学习</tag>
        <tag>图像分割</tag>
        <tag>图像分类</tag>
      </tags>
  </entry>
  <entry>
    <title>序</title>
    <url>/Zlog/%E5%BA%8F/</url>
    <content><![CDATA[<p>不积跬步，无以至千里。 <span id="more"></span>
学习很重要，思考很重要，整理同样也很重要。因此，本博客专门用于学习过程中的整理和记录，便于温故而知新。</p>
]]></content>
  </entry>
  <entry>
    <title>Ubuntu 自定义路径下安装 SLEPc/PETSc 以及 BLAS/LAPACK 科学计算库</title>
    <url>/Zlog/slepc/</url>
    <content><![CDATA[<h1 id="引言">引言</h1>
<p>最近在计算矩阵特征值的问题上，用到了 SLEPc（Scalable Library for
Eigenvalue Problem Computations），SLEPc
可用于超大稀疏矩阵特征值的快速并行计算，也可以用于其他 SVD
分解等常用矩阵计算。SLEPc 的安装依赖于其他通用科学计算库，比如
PETSc，BLAS/LAPACK
等，环境配置稍显复杂，因此，记录环境配置过程，以备后用。</p>
<span id="more"></span>
<h1 id="依赖关系">依赖关系</h1>
<p>SLEPc 是一个开源项目，可以在这里找到 <a
href="https://github.com/firedrakeproject/slepc/">https://github.com/firedrakeproject/slepc/</a>
，有非常详细的使用说明（documentation），使用友好。SLEPc 依赖于
PETSc，而 PETSc 依赖于 BLAS/LAPACK，因此，我们需要一一安装依赖项。</p>
<h1 id="blaslapack">BLAS/LAPACK</h1>
<p>BLAS（Basic Linear Algebra
Subprograms）定义了一系列矩阵、向量之间的基础运算的接口标准（API），Netlib
实现了 BLAS 的这些接口，得到的库也叫 BLAS。以 BLAS 为基础，Netlib
增加了更多高级的矩阵、向量运算，如分解、求逆、特征值等，并且实现了这些高级接口，于是有了
LAPACK（Linear Algebra PackAage）。这两个库都是用 Fortran
语言开发的（另外插一句，CBLAS 和 CLAPACK 是 BLAS 和 LAPACK 的 C
语言接口）。</p>
<p>默认安装方式 <a href="#refer-anchor-1"><sup>[1]</sup></a>
为（没有试过... 应该不会有什么问题...） <figure class="highlight q"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="built_in">get</span> install libblas-<span class="built_in">dev</span></span><br><span class="line">sudo apt-<span class="built_in">get</span> install liblapack-<span class="built_in">dev</span></span><br></pre></td></tr></table></figure> 默认位置在
<figure class="highlight awk"><table><tr><td class="code"><pre><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>libblas.a </span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>libblas.so </span><br><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/lib/</span>libblas.a</span><br><span class="line"></span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>liblapack.so </span><br><span class="line"><span class="regexp">/usr/</span>lib<span class="regexp">/x86_64-linux-gnu/</span>liblapack.a</span><br><span class="line"><span class="regexp">/usr/</span>local<span class="regexp">/lib/</span>liblapack.a</span><br></pre></td></tr></table></figure></p>
<p>因为我需要安装在自定义路径中，所以下面进行一些自定义配置，如果不需要自定义路径，可以直接跳到
<a href="#title-anchor-PETSc">下一节</a>。</p>
<h2 id="安装-fortran-语言的编译器-gfortran">安装 Fortran 语言的编译器
gfortran</h2>
<figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">sudo apt-<span class="built_in">get</span> install gfortran</span><br></pre></td></tr></table></figure>
<h2 id="安装-fftw-2">安装 FFTW <a
href="#refer-anchor-2"><sup>[2]</sup></a></h2>
<p><strong>i. 下载 FFTW</strong></p>
<p><a
href="http://www.fftw.org/download.html">http://www.fftw.org/download.html</a></p>
<p><strong>ii. 安装 FFTW</strong> <figure class="highlight jboss-cli"><table><tr><td class="code"><pre><span class="line">tar -zxvf fftw-3.3.10.tar.gz</span><br><span class="line"><span class="keyword">cd</span> fftw-3.3.10/</span><br><span class="line"><span class="comment"># 下面尽可能多的使用了指令集优化，不需要的化可以去掉相应的选项 </span></span><br><span class="line"><span class="comment"># cat /proc/cpuinfo 可以查看 cpu 支持的指令集 </span></span><br><span class="line"><span class="string">./configure</span> <span class="params">--prefix=/your/path/to/install</span> <span class="params">--enable-shared</span> <span class="params">--enable-static</span> <span class="params">--enable-single</span> <span class="params">--enable-sse</span> <span class="params">--enable-sse2</span> <span class="params">--enable-avx</span> <span class="params">--enable-avx2</span> <span class="params">--enable-fma</span> <span class="params">--enable-mpi</span> <span class="params">--enable-threads</span> <span class="params">--enable-openmp</span> </span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<!-- ./configure --prefix=/opt/hmi_depends/algorithm_depends/fftw --enable-shared --enable-static --enable-single --enable-sse --enable-sse2 --enable-avx --enable-avx2 --enable-fma --enable-mpi --enable-threads --enable-openmp  --></p>
<h2 id="安装-blaslapack-2">安装 BLAS/LAPACK <a
href="#refer-anchor-2"><sup>[2]</sup></a></h2>
<p><strong>i. 确保 cmake 和 gfortran 已经安装 </strong></p>
<p><strong>ii. 下载 LAPACK</strong></p>
<p><a
href="https://netlib.org/lapack/">https://netlib.org/lapack/</a></p>
<p>幸运的是 LAPACK 中已经包含了 BLAS，所以不用重复下载。</p>
<p><strong>iii. 安装 LAPACK</strong></p>
<p>解压 <figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">tar</span> -zxvf lapack-<span class="number">3</span>.<span class="number">11</span>.tar.gz</span><br><span class="line"><span class="attribute">cd</span> lapack-<span class="number">3</span>.<span class="number">11</span></span><br></pre></td></tr></table></figure> 解压之后，它里面会含有 BLAS，CBLAS，LAPACKE
等文件夹。新建 <code>make.inc</code> 文件 <figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cp</span> <span class="keyword">make</span>.inc.example <span class="keyword">make</span>.inc</span><br></pre></td></tr></table></figure> 如果是使用
gfortran，则无须更改 <code>make.inc</code>
里的内容，否则需要根据系统环境和编译器修改文件里对应的选项。</p>
<p>LAPACK 依赖 BLAS，在编译 LAPACK 前需要编译 BLAS
包，而默认并不编译，因此，需要修改一下 <code>makefile</code>
<figure class="highlight nginx"><table><tr><td class="code"><pre><span class="line"><span class="attribute">gedit</span> Makefile</span><br><span class="line"><span class="comment"># or </span></span><br><span class="line"><span class="comment"># vim Makefile</span></span><br></pre></td></tr></table></figure> 将第 <em>12~13</em> 行 <figure class="highlight crystal"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">lib</span>: <span class="title">lapacklib</span> <span class="title">tmglib</span></span></span><br><span class="line"><span class="comment">#lib: blaslib variants lapacklib tmglib</span></span><br></pre></td></tr></table></figure> 修改为 <figure class="highlight avrasm"><table><tr><td class="code"><pre><span class="line"><span class="meta">#lib: lapacklib tmglib</span></span><br><span class="line"><span class="symbol">lib:</span> blaslib variants lapacklib tmglib</span><br></pre></td></tr></table></figure>
然后，进行编译 <figure class="highlight ebnf"><table><tr><td class="code"><pre><span class="line"><span class="attribute">make</span></span><br></pre></td></tr></table></figure> <strong>【重要】</strong> 接下来，进入
<code>LAPACKE</code> 目录并再次编译 <figure class="highlight vim"><table><tr><td class="code"><pre><span class="line"><span class="keyword">cd</span> LAPACKE</span><br><span class="line"><span class="keyword">make</span></span><br></pre></td></tr></table></figure> 在
<code>lapack-3.11</code>
目录下生成如下四个静态库，<code>liblapack.a, liblapacke.a, librefblas.a, libtmglib.a</code>
则表示编译成功，将这四个静态库拷贝到自定义路径下的 <code>lib</code>
路径，同时将 <code>LAPACKE/include</code>
目录下的头文件拷贝到自定义路径下的 <code>include</code> 目录。</p>
<h1 id="安装-mpich">安装 MPICH</h1>
<p>PETSc 还依赖于 MPICH。</p>
<p><strong>i. 下载 MPICH</strong></p>
<p><a
href="https://www.mpich.org/downloads/">https://www.mpich.org/downloads/</a></p>
<p><strong>ii. 安装 MPICH</strong></p>
<p>解压并编译 <figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">tar -zxvf mpich-<span class="number">4.1</span>.<span class="number">1</span>.tar.gz</span><br><span class="line">cd mpich-<span class="number">4.1</span>.<span class="number">1</span></span><br><span class="line">.<span class="regexp">/configure --prefix=/y</span>our<span class="regexp">/path/</span>to/install</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></p>
<h1 id="petsc-和-slepc-版本">PETSc 和 SLEPc 版本</h1>
<p>由于 SLEPc 是基于 PETSc 的，所以需要先安装 PETSc，再安装
SLEPc。与此同时，要确保所下载的 PETSc 和 SLEPc 的版本能够符合 <a
href="https://slepc.upv.es/download/changes.htm">版本对应表</a>。</p>
<h1 id="安装-petsc">安装 PETSc</h1>
<div id="title-anchor-PETSc">

</div>
<p><strong>i. 下载 PETSc</strong></p>
<p><a
href="https://petsc.org/release/install/download/">https://petsc.org/release/install/download/</a></p>
<p><strong>ii. 安装 PETSc</strong> <figure class="highlight awk"><table><tr><td class="code"><pre><span class="line">tar -zxvf petsc-<span class="number">3.18</span>.<span class="number">5</span>.tar.gz</span><br><span class="line">cd petsc-<span class="number">3.18</span>.<span class="number">5</span></span><br><span class="line">.<span class="regexp">/configure --with-shared-libraries=0 --with-blas-lib=/y</span>our<span class="regexp">/blas/</span>path<span class="regexp">/to/</span>librefblas.a --with-lapack-lib=<span class="regexp">/your/</span>blas<span class="regexp">/path/</span>to<span class="regexp">/liblapack.a --with-mpi-dir=/y</span>our<span class="regexp">/blas/</span>path<span class="regexp">/to/m</span>pi</span><br><span class="line">make check all</span><br></pre></td></tr></table></figure> 如果以后需要使用 PETSc
的库，可将 <code>include</code> 目录下的所有文件拷贝到安装目录
<code>include</code> 下，将
<code>arch-linux-c-debug/lib/libpetsc.a</code> 拷贝到安装目录
<code>lib</code> 下。</p>
<!-- ./configure --prefix=/opt/hmi_depends/algorithm_depends --with-shared-libraries=0 --with-blas-lib=/opt/hmi_depends/algorithm_depends/libs/lapack/librefblas.a --with-lapack-lib=/opt/hmi_depends/algorithm_depends/libs/lapack/liblapack.a --with-mpi-dir=/opt/hmi_depends/algorithm_depends/mpi -->
<h1 id="安装-slepc">安装 SLEPc</h1>
<p><strong>i. 下载 SLEPc</strong></p>
<p><a
href="https://slepc.upv.es/download/">https://slepc.upv.es/download/</a></p>
<p><strong>ii. 安装 SLEPc</strong> <figure class="highlight routeros"><table><tr><td class="code"><pre><span class="line">tar -zxvf slepc-3.18.5.tar.gz</span><br><span class="line">cd petsc-3.18.5</span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">PETSC_DIR</span>=/path/to/  # 此处应为 PETSc 解压并且编译过的路径，如我这里为 petsc-3.18.5 的绝对路径 </span><br><span class="line"><span class="built_in">export</span> <span class="attribute">PETSC_ARCH</span>=/path/to/arch/of/petsc  # 此处应为 PETSc 编译时确定的当前编译版本的库的绝对路径，可以在 petsc-3.18.5 路径下找到 arch 开头的文件夹，如我这里为 arch-linux-c-<span class="built_in">debug</span></span><br><span class="line"><span class="built_in">export</span> <span class="attribute">SLEPC_DIR</span>=/path/to/slepc-3.18.2  # 此处应为解压的 SLEPc 的路径 </span><br><span class="line"></span><br><span class="line">./configure</span><br><span class="line">make</span><br><span class="line">check</span><br></pre></td></tr></table></figure> 最后将
<code>include</code> 目录下的所有文件拷贝到安装目录 <code>include</code>
下，将 <code>arch-linux-c-debug/lib/libslepc.a</code> 拷贝到安装目录
<code>lib</code> 下。</p>
<!-- ./configure --with --with-blas-lib=/opt/hmi_depends/algorithm_depends/libs/lapack/librefblas.a --with-lapack-lib=/opt/hmi_depends/algorithm_depends/libs/lapack/liblapack.a --with-mpi-dir=/opt/hmi_depends/algorithm_depends/mpi -->
<h1 id="参考">参考</h1>
<div id="refer-anchor-1">

</div>
<ul>
<li>[1] <span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC80NDA5NTkyODcv">Ubuntu
BLAS/LAPACK 安装<i class="fa fa-external-link-alt"></i></span>
<div id="refer-anchor-2">

</div></li>
<li>[2] <span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vYmFieWNsYXNzL3AvMTYzNTg1ODkuaHRtbA==">非
ROOT 路径安装 BLAS/LAPACK<i class="fa fa-external-link-alt"></i></span></li>
</ul>
]]></content>
      <categories>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
        <tag>BLAS/LAPACK</tag>
        <tag>PETSc</tag>
        <tag>SLEPc</tag>
        <tag>快速矩阵计算</tag>
        <tag>科学计算包</tag>
      </tags>
  </entry>
</search>
